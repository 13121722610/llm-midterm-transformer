# ã€LLM Midterm Transformer - æ–‡æœ¬ç”Ÿæˆä¸æ¶ˆèå®éªŒã€‘
åŸºäºTransformerçš„èå£«æ¯”äºšæ–‡æœ¬ç”Ÿæˆä¸æ¨¡å‹æ¶æ„åˆ†æ
Course assignment: decoder-only Transformer (Tiny Shakespeare)

# ğŸ“‹ é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„Transformeræ–‡æœ¬ç”Ÿæˆç³»ç»Ÿï¼ŒåŒ…å«Decoder-Only Transformeræ¶æ„ã€‚  
é€šè¿‡å±‚æ•°æ¶ˆèå®éªŒï¼ˆ2/4/6å±‚å¯¹æ¯”ï¼‰å’Œç”Ÿæˆè´¨é‡åˆ†æï¼Œæ·±å…¥æ¢ç©¶Transformeræ¶æ„è®¾è®¡å¯¹æ–‡æœ¬ç”Ÿæˆæ€§èƒ½çš„å½±å“ã€‚é¡¹ç›®ä½¿ç”¨Tiny Shakespeareæ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

# ğŸ¯ æ ¸å¿ƒç‰¹æ€§
Decoder-Onlyæ¶æ„: ä¼˜åŒ–çš„è‡ªå›å½’æ–‡æœ¬ç”Ÿæˆæ¨¡å‹  
æ™ºèƒ½é‡‡æ ·ç­–ç•¥: Top-k + Top-p æ··åˆé‡‡æ ·ï¼Œæå‡ç”Ÿæˆå¤šæ ·æ€§  
å±‚æ•°æ¶ˆèå®éªŒ: ç³»ç»Ÿåˆ†æä¸åŒå±‚æ•°æ¶æ„çš„æ€§èƒ½å·®å¼‚  
å®Œæ•´å®éªŒæµç¨‹: ä¸€é”®å¤ç°è®­ç»ƒã€è¯„ä¼°ã€ç”Ÿæˆå…¨æµç¨‹  

# ğŸš€ ç¯å¢ƒé…ç½®
åˆ›å»ºcondaç¯å¢ƒ  
conda create -n llm_toy python=3.10 -y  
conda activate llm_toy  
å®‰è£…æ ¸å¿ƒä¾èµ–  
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  
pip install numpy tqdm matplotlib requests pandas  

ã€è¿è¡Œæ–¹æ³•ã€‘ï¼š
ä¸€é”®è¿è¡Œå®Œæ•´å®éªŒï¼š  
èµ‹äºˆæ‰§è¡Œæƒé™  
chmod +x run.sh  
è¿è¡Œå®Œæ•´å®éªŒæµç¨‹  
./run.sh  

æˆ–è€…åˆ†æ­¥æ‰§è¡Œï¼š  
1ã€æ•°æ®å‡†å¤‡  
cd src  
python -c "from data import load_data; tokenizer, train_data, val_data = load_data()"  
2ã€æ¨¡å‹è®­ç»ƒ  
python train.py  
3ã€æ¶ˆèå®éªŒ  
python ablation_study.py  
4ã€ç”Ÿæˆå¯¹æ¯”  
python compare_generation.py  
5ã€å•æ¬¡ç”Ÿæˆ  
python generate.py  

# ğŸ§  æ¨¡å‹æ¶æ„
Decoder-Only Transformer  
æœ¬é¡¹ç›®ä¸»è¦é‡‡ç”¨Decoder-Only Transformeræ¶æ„ï¼Œä¸“ä¸ºè‡ªå›å½’æ–‡æœ¬ç”Ÿæˆè®¾è®¡ï¼š  
å±‚æ•°é…ç½®: 2å±‚/4å±‚/6å±‚ (æ¶ˆèå®éªŒå¯¹æ¯”)  
éšè—ç»´åº¦: 256  
æ³¨æ„åŠ›å¤´æ•°: 8å¤´å¤šå¤´æ³¨æ„åŠ›  
å‰é¦ˆç½‘ç»œ: 1024ç»´  
ä½ç½®ç¼–ç : å¯å­¦ä¹ ä½ç½®åµŒå…¥  
è¯æ±‡è¡¨å¤§å°: ~65ä¸ªå­—ç¬¦ (åŸºäºShakespeareæ•°æ®é›†)  

# ğŸ”¬ å®éªŒè®¾è®¡
æ¶ˆèå®éªŒç›®æ ‡ï¼š  
æ¶æ„æ·±åº¦å½±å“: åˆ†æå±‚æ•°å¯¹æ¨¡å‹è¡¨è¾¾èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›çš„å½±å“  
è®­ç»ƒæ•ˆç‡: æ¯”è¾ƒä¸åŒå¤æ‚åº¦æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œè®¡ç®—éœ€æ±‚  
ç”Ÿæˆè´¨é‡: è¯„ä¼°ä¸åŒæ¶æ„çš„æ–‡æœ¬è¿è´¯æ€§ã€åˆ›é€ æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§  

è¯„ä¼°æŒ‡æ ‡ï¼š  
ä¸»è¦æŒ‡æ ‡: éªŒè¯é›†å›°æƒ‘åº¦(Perplexity)  
ç”Ÿæˆè¯„ä¼°: æ–‡æœ¬è¿è´¯æ€§ã€å¤šæ ·æ€§ã€è¯­ä¹‰åˆç†æ€§  
æ•ˆç‡æŒ‡æ ‡: è®­ç»ƒæ—¶é—´ã€æ¨ç†é€Ÿåº¦ã€å†…å­˜å ç”¨  

å®éªŒè®¾ç½®ï¼š  
æ•°æ®é›†: Tiny Shakespeare (1MBæ–‡æœ¬)  
è®­ç»ƒ/éªŒè¯åˆ†å‰²: 90%/10%  
æ‰¹é‡å¤§å°: 32  
ä¼˜åŒ–å™¨: AdamW (lr=1e-4, weight_decay=0.01)  
æ—©åœç­–ç•¥: 5è½®æ— æ”¹å–„åœæ­¢  

# ğŸ“ˆ å¯è§†åŒ–è¾“å‡º
é¡¹ç›®è‡ªåŠ¨ç”Ÿæˆä»¥ä¸‹åˆ†æå›¾è¡¨ï¼š  
è®­ç»ƒæ›²çº¿å›¾: æŸå¤±å’Œå›°æƒ‘åº¦éšè®­ç»ƒè½®æ¬¡çš„å˜åŒ–  
æ¶ˆèå¯¹æ¯”å›¾: ä¸åŒå±‚æ•°æ¶æ„çš„æ€§èƒ½æŸ±çŠ¶å›¾å¯¹æ¯”  
å‚æ•°é‡åˆ†æ: æ¨¡å‹å¤æ‚åº¦ä¸æ€§èƒ½çš„å…³ç³»  
ç”Ÿæˆæ ·æœ¬å¯¹æ¯”: å„æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„å®šæ€§åˆ†æ  

# ğŸ› ï¸ å¼€å‘è¯´æ˜
ç›®å½•ç»“æ„ï¼š
llm-midterm-transformer/  
â”œâ”€â”€ ğŸ“‚ src/                           # æºä»£ç ç›®å½•  
â”‚   â”œâ”€â”€ ğŸ“‚ checkpoints/              # æ¨¡å‹æƒé‡å­˜å‚¨   
â”‚   â”‚   â”œâ”€â”€ decoder_only_improved_best.pt          # 6å±‚5è½®æ¨¡å‹  
â”‚   â”‚   â”œâ”€â”€ ablation_layers_2_best.pt              # 2å±‚3è½®æ¶ˆèå®éªŒæ¨¡å‹  
â”‚   â”‚   â”œâ”€â”€ ablation_layers_4_best.pt              # 4å±‚3è½®æ¶ˆèå®éªŒæ¨¡å‹  
â”‚   â”‚   â””â”€â”€ ablation_layers_6_best.pt              # 6å±‚3è½®æ¶ˆèå®éªŒæ¨¡å‹  
â”‚   â”œâ”€â”€ ğŸ“‚ results/                  # å®éªŒç»“æœè¾“å‡º  
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ figures/              # å¯è§†åŒ–å›¾è¡¨  
â”‚   â”‚   â”‚   â”œâ”€â”€ decoder_only_improved_final_training_curve.png          # å®Œæ•´è®­ç»ƒæ›²çº¿  
â”‚   â”‚   â”‚   â”œâ”€â”€ layer_ablation_comparison.png                  # æ¶ˆèå®éªŒä¸­â½‚å›¾è¡¨  
â”‚   â”‚   â”‚   â””â”€â”€ layer_ablation_comparison_english.png          # æ¶ˆèå®éªŒè‹±â½‚å›¾è¡¨  
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ tables/               # æ•°æ®è¡¨æ ¼  
â”‚   â”‚   â”‚   â”œâ”€â”€ decoder_only_improved_final_results.csv                 # 6å±‚æ¨¡å‹æœ€ç»ˆç»“æœ  
â”‚   â”‚   â”‚   â”œâ”€â”€ layer_ablation_results.csv                     # æ¶ˆèå®éªŒæ•°æ®  
â”‚   â”‚   â”‚   â””â”€â”€ generation_comparison.csv                      # â½£æˆå¯¹â½ç»“æœ  
â”‚   â”‚   â””â”€â”€ ğŸ“‚ logs/                 # è®­ç»ƒâ½‡å¿—  
â”‚   â”‚       â”œâ”€â”€ decoder_only_improved_log.json                          # 6å±‚æ¨¡å‹è®­ç»ƒâ½‡å¿—  
â”‚   â”œâ”€â”€ data.py                      # æ•°æ®åŠ è½½ä¸é¢„å¤„ç†  
â”‚   â”œâ”€â”€ model.py                     # Transformeræ¨¡å‹å®šä¹‰  
â”‚   â”œâ”€â”€ train.py                     # æ¨¡å‹è®­ç»ƒè„šæœ¬  
â”‚   â”œâ”€â”€ generate.py                  # æ–‡æœ¬ç”Ÿæˆæ¥å£  
â”‚   â”œâ”€â”€ ablation_study.py            # æ¶ˆèå®éªŒåˆ†æ  
â”‚   â””â”€â”€ compare_generation.py        # ç”Ÿæˆè´¨é‡å¯¹æ¯”  
â”œâ”€â”€ ğŸ“‚ scripts/                      # è„šæœ¬ç›®å½•  
â”‚   â””â”€â”€ run.sh                       # â¼€é”®æ‰§â¾è„šæœ¬  
â”œâ”€â”€ README.md                        # é¡¹â½¬è¯´æ˜â½‚æ¡£  
â””â”€â”€ requirements.txt                 # Pythonä¾èµ–åˆ—è¡¨  

ä»£ç ç»“æ„ï¼š  
data.py: æ•°æ®å¤„ç†ç®¡é“ï¼ŒåŒ…å«å­—ç¬¦çº§tokenizer  
model.py: Transformeræ¨¡å‹å®šä¹‰ï¼Œæ”¯æŒçµæ´»çš„å±‚æ•°é…ç½®  
train.py: è®­ç»ƒå¾ªç¯ã€éªŒè¯å’Œæ¨¡å‹ä¿å­˜  
generate.py: æ–‡æœ¬ç”Ÿæˆæ¥å£ï¼Œæ”¯æŒå¤šç§é‡‡æ ·ç­–ç•¥  
compare_generation.py: ç”Ÿæˆè´¨é‡å¯¹æ¯”åˆ†ææ¨¡å—  
ablation_study.py: æ¶ˆèå®éªŒçš„è‡ªåŠ¨åŒ–æ‰§è¡Œå’Œåˆ†æ  


# ğŸ‘¥ è´¡çŒ®è€…
å­£æœˆå« - 25120410 - é¡¹ç›®å¼€å‘ä¸å®éªŒè®¾è®¡
