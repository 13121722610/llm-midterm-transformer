#!/bin/bash

# =============================================================================
# LLM Midterm Transformer - å®Œæ•´å¤ç°è„šæœ¬
# ä½œè€…ï¼šå­£æœˆå«
# å­¦å·ï¼š25120410
# æè¿°ï¼šä¸€é”®å¤ç°Transformerè®­ç»ƒå’Œç”Ÿæˆå…¨è¿‡ç¨‹
# =============================================================================

set -e  # é‡åˆ°ä»»ä½•é”™è¯¯ç«‹å³é€€å‡º

echo "================================================================"
echo "           LLM Midterm Transformer å¤ç°è„šæœ¬"
echo "================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
echo ""

# ============================ å‚æ•°é…ç½® ============================
SEED=42
PROJECT_DIR="/data0/yhji/llm-midterm-transformer"
PYTHON_PATH="$PROJECT_DIR/src"
EXPERIMENT_MODE=${1:-"ablation"}  # é»˜è®¤è¿›è¡Œæ¶ˆèå®éªŒ

# ============================ ç¯å¢ƒæ£€æŸ¥ ============================
echo "=== æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥ ==="

# æ£€æŸ¥condaç¯å¢ƒ
if ! conda info --envs | grep -q "llm_toy"; then
    echo "åˆ›å»ºcondaç¯å¢ƒ: llm_toy"
    conda create -n llm_toy python=3.10 -y
else
    echo "æ‰¾åˆ°condaç¯å¢ƒ: llm_toy"
fi

# æ¿€æ´»ç¯å¢ƒ
echo "æ¿€æ´»condaç¯å¢ƒ..."
eval "$(conda shell.bash hook)"
conda activate llm_toy

# æ£€æŸ¥Python
echo "Pythonç‰ˆæœ¬: $(python --version)"

# ============================ ä¾èµ–å®‰è£… ============================
echo ""
echo "=== æ­¥éª¤2: å®‰è£…ä¾èµ– ==="

# æ£€æŸ¥æ˜¯å¦æœ‰requirements.txt
if [ -f "$PROJECT_DIR/requirements.txt" ]; then
    echo "ä½¿ç”¨requirements.txtå®‰è£…ä¾èµ–..."
    pip install -r "$PROJECT_DIR/requirements.txt"
else
    echo "æœªæ‰¾åˆ°requirements.txtï¼Œå®‰è£…æ ¸å¿ƒä¾èµ–..."
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    pip install numpy pandas matplotlib requests tqdm tokenizers
fi

# ============================ ç¯å¢ƒè®¾ç½® ============================
echo ""
echo "=== æ­¥éª¤3: ç¯å¢ƒè®¾ç½® ==="

# è®¾ç½®Pythonè·¯å¾„
export PYTHONPATH="$PROJECT_DIR/src:$PYTHONPATH"
export PYTHONHASHSEED=$SEED

# æ£€æŸ¥å¹¶æ˜¾ç¤ºç°æœ‰ç›®å½•
echo "é¡¹ç›®ç›®å½•ç»“æ„:"
for dir in "checkpoints" "results/figures" "results/tables" "results/logs" "data"; do
    if [ -d "$PROJECT_DIR/$dir" ]; then
        echo "âœ… $PROJECT_DIR/$dir/ (å·²å­˜åœ¨)"
    else
        echo "ğŸ“ åˆ›å»ºç›®å½•: $PROJECT_DIR/$dir/"
        mkdir -p "$PROJECT_DIR/$dir"
    fi
done

echo "é¡¹ç›®ç›®å½•: $PROJECT_DIR"
echo "Pythonè·¯å¾„: $PYTHONPATH"
echo "éšæœºç§å­: $SEED"
echo "å®éªŒæ¨¡å¼: $EXPERIMENT_MODE"

# ============================ è®­ç»ƒå‰æ£€æŸ¥ ============================
echo ""
echo "=== æ­¥éª¤4: è®­ç»ƒçŠ¶æ€æ£€æŸ¥ ==="

TRAINING_NEEDED=true

# æ£€æŸ¥æ˜¯å¦å·²ç»è®­ç»ƒå®Œæˆ
check_training_complete() {
    if [ -f "$PROJECT_DIR/src/results/tables/ablation_study.csv" ] || [ -f "$PROJECT_DIR/results/tables/ablation_study.csv" ]; then
        echo "âœ… å‘ç°å·²å®Œæˆçš„è®­ç»ƒç»“æœï¼"
        echo "å½“å‰è®­ç»ƒçŠ¶æ€:"
        
        if [ -f "$PROJECT_DIR/src/results/tables/ablation_study.csv" ]; then
            RESULTS_DIR="$PROJECT_DIR/src/results"
        else
            RESULTS_DIR="$PROJECT_DIR/results"
        fi
        
        python -c "
import pandas as pd
try:
    df = pd.read_csv('$RESULTS_DIR/tables/ablation_study.csv')
    full_ppl = df[df['model_type']=='full']['best_val_ppl'].values[0]
    decoder_ppl = df[df['model_type']=='decoder_only']['best_val_ppl'].values[0]
    improvement = (decoder_ppl - full_ppl) / decoder_ppl * 100
    print('ğŸ“Š ç°æœ‰è®­ç»ƒç»“æœ:')
    print(f'   å®Œæ•´Transformer - å›°æƒ‘åº¦: {full_ppl:.3f}')
    print(f'   Decoder-Only - å›°æƒ‘åº¦: {decoder_ppl:.3f}')
    print(f'   ğŸ¯ æ€§èƒ½æå‡: {improvement:.1f}%')
    print('')
    print('ğŸ’¡ æç¤º: è®­ç»ƒå·²å®Œæˆï¼Œè·³è¿‡è®­ç»ƒæ­¥éª¤')
except Exception as e:
    print('è¯»å–è®­ç»ƒç»“æœæ—¶å‡ºé”™:', e)
"
        return 0  # è®­ç»ƒå·²å®Œæˆ
    else
        echo "âŒ æœªæ‰¾åˆ°å®Œæ•´çš„è®­ç»ƒç»“æœ"
        return 1  # éœ€è¦è®­ç»ƒ
    fi
}

# æ‰§è¡Œè®­ç»ƒæ£€æŸ¥
if check_training_complete; then
    TRAINING_NEEDED=false
    echo "è·³è¿‡è®­ç»ƒæ­¥éª¤ï¼Œç›´æ¥è¿›è¡Œç»“æœå±•ç¤º..."
else
    echo "å¼€å§‹æ–°çš„è®­ç»ƒ..."
fi

# ============================ æ•°æ®å‡†å¤‡ ============================
echo ""
echo "=== æ­¥éª¤5: æ•°æ®å‡†å¤‡ ==="

cd "$PROJECT_DIR"

# ä¸‹è½½æ•°æ®
echo "ä¸‹è½½è®­ç»ƒæ•°æ®..."
python -c "
from src.data import load_data
print('æ­£åœ¨ä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®...')
tokenizer, train_data, val_data = load_data()
print(f'æ•°æ®åŠ è½½å®Œæˆ!')
print(f'è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}')
print(f'è®­ç»ƒæ•°æ®é•¿åº¦: {len(train_data)}')
print(f'éªŒè¯æ•°æ®é•¿åº¦: {len(val_data)}')
"

# ============================ æ¨¡å‹è®­ç»ƒ ============================
echo ""
echo "=== æ­¥éª¤6: æ¨¡å‹è®­ç»ƒ ==="

if [ "$TRAINING_NEEDED" = true ]; then
    cd "$PROJECT_DIR/src"

    # æ­£ç¡®çš„GPUæ£€æŸ¥
    echo "GPUçŠ¶æ€:"
    python -c "
import torch
if torch.cuda.is_available():
    print(f'CUDAå¯ç”¨: True')
    print(f'GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}')
else:
    print(f'CUDAå¯ç”¨: False')
    print(f'GPUè®¾å¤‡: CPU')
"

    # æ ¹æ®æ¨¡å¼é€‰æ‹©è®­ç»ƒæ–¹å¼
    case $EXPERIMENT_MODE in
        "ablation")
            echo "å¼€å§‹æ¶ˆèå®éªŒï¼ˆå®Œæ•´Transformer vs Decoder-Onlyï¼‰..."
            echo "è¿™å°†éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…..."
            python train.py ablation
            ;;
        "full")
            echo "å¼€å§‹è®­ç»ƒå®Œæ•´Transformeræ¨¡å‹..."
            python train.py full
            ;;
        "decoder_only")
            echo "å¼€å§‹è®­ç»ƒDecoder-Onlyæ¨¡å‹..."
            python train.py decoder_only
            ;;
        *)
            echo "æœªçŸ¥æ¨¡å¼: $EXPERIMENT_MODEï¼Œä½¿ç”¨é»˜è®¤æ¶ˆèå®éªŒ"
            python train.py ablation
            ;;
    esac
else
    echo "âœ… è·³è¿‡è®­ç»ƒæ­¥éª¤ - æ¨¡å‹å·²è®­ç»ƒå®Œæˆ"
fi

# ============================ ç»“æœéªŒè¯ ============================
echo ""
echo "=== æ­¥éª¤7: è®­ç»ƒç»“æœéªŒè¯ ==="

# ç¡®å®šç»“æœç›®å½•
if [ -d "$PROJECT_DIR/src/results" ]; then
    RESULTS_DIR="$PROJECT_DIR/src/results"
elif [ -d "$PROJECT_DIR/results" ]; then
    RESULTS_DIR="$PROJECT_DIR/results"
else
    RESULTS_DIR=""
fi

if [ -n "$RESULTS_DIR" ]; then
    echo "ğŸ“Š è®­ç»ƒç»“æœæ±‡æ€»:"
    
    # æ£€æŸ¥å›¾è¡¨æ–‡ä»¶
    if ls "$RESULTS_DIR/figures"/*.png 1> /dev/null 2>&1; then
        echo "âœ… è®­ç»ƒæ›²çº¿å›¾:"
        ls "$RESULTS_DIR/figures"/*.png
    else
        echo "âŒ æœªæ‰¾åˆ°è®­ç»ƒæ›²çº¿å›¾"
    fi
    
    # æ£€æŸ¥æ•°æ®è¡¨æ ¼
    if ls "$RESULTS_DIR/tables"/*.csv 1> /dev/null 2>&1; then
        echo "âœ… ç»“æœè¡¨æ ¼:"
        ls "$RESULTS_DIR/tables"/*.csv
        echo ""
        echo "ğŸ“ˆ æœ€ç»ˆç»“æœ:"
        python -c "
import pandas as pd
import glob
import os

csv_files = glob.glob('$RESULTS_DIR/tables/*final_results.csv')
for file in csv_files:
    df = pd.read_csv(file)
    filename = os.path.basename(file)
    print(f'æ–‡ä»¶: {filename}')
    for col in df.columns:
        if 'ppl' in col.lower() or 'loss' in col.lower():
            print(f'  {col}: {df[col].values[0]:.4f}')
    print()
        "
    else
        echo "âŒ æœªæ‰¾åˆ°ç»“æœè¡¨æ ¼"
    fi
else
    echo "âŒ æœªæ‰¾åˆ°resultsç›®å½•"
fi

# ============================ æ–‡æœ¬ç”Ÿæˆ ============================
echo ""
echo "=== æ­¥éª¤8: æ–‡æœ¬ç”Ÿæˆæµ‹è¯• ==="

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
models_to_test=()

# æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„æ¨¡å‹æ–‡ä»¶ä½ç½®
if [ -f "$PROJECT_DIR/src/checkpoints/full_transformer_best.pt" ]; then
    models_to_test+=("full_transformer")
    MODEL_DIR="$PROJECT_DIR/src/checkpoints"
elif [ -f "$PROJECT_DIR/checkpoints/full_transformer_best.pt" ]; then
    models_to_test+=("full_transformer")
    MODEL_DIR="$PROJECT_DIR/checkpoints"
fi

if [ -f "$PROJECT_DIR/src/checkpoints/decoder_only_best.pt" ]; then
    models_to_test+=("decoder_only")
    MODEL_DIR="$PROJECT_DIR/src/checkpoints"
elif [ -f "$PROJECT_DIR/checkpoints/decoder_only_best.pt" ]; then
    models_to_test+=("decoder_only")
    MODEL_DIR="$PROJECT_DIR/checkpoints"
fi

if [ ${#models_to_test[@]} -eq 0 ]; then
    echo "âŒ é”™è¯¯: æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶"
    echo "è¯·å…ˆè¿è¡Œè®­ç»ƒæ­¥éª¤"
    exit 1
fi

echo "æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: ${models_to_test[*]}"
echo "å¼€å§‹ç”Ÿæˆæµ‹è¯•..."

# æµ‹è¯•ä¸åŒçš„prompt
prompts=("To be, or not to be" "Once upon a time" "The future of AI" "Love is" "In the beginning")

for model_type in "${models_to_test[@]}"; do
    echo ""
    echo "ğŸ” æµ‹è¯•æ¨¡å‹: $model_type"
    echo "========================================"
    
    for prompt in "${prompts[@]}"; do
        echo ""
        echo "Prompt: \"$prompt\""
        echo "ç”Ÿæˆç»“æœ:"
        
        # è°ƒç”¨ç”Ÿæˆè„šæœ¬
        cd "$PROJECT_DIR/src"
        python -c "
import torch
import sys
import os
sys.path.append('.')

try:
    from generate import generate_full_transformer, generate_decoder_only
    from data import load_data
    from model import FullTransformer, DecoderOnlyTransformer
    
    # åŠ è½½tokenizerå’Œæ¨¡å‹
    tokenizer, _, _ = load_data()
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    model_type = '$model_type'
    prompt = '$prompt'
    model_dir = '$MODEL_DIR'
    
    if model_type == 'full_transformer':
        model = FullTransformer(tokenizer.vocab_size)
        model_path = os.path.join(model_dir, 'full_transformer_best.pt')
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.to(device)
        result = generate_full_transformer(model, tokenizer, prompt, max_new_tokens=50, temperature=0.8)
    else:
        model = DecoderOnlyTransformer(tokenizer.vocab_size)
        model_path = os.path.join(model_dir, 'decoder_only_best.pt')
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.to(device)
        result = generate_decoder_only(model, tokenizer, prompt, max_new_tokens=50, temperature=0.8)
    
    print(result)
except Exception as e:
    print(f'ç”Ÿæˆé”™è¯¯: {e}')
    import traceback
    traceback.print_exc()
        "
        echo "----------------------------------------"
    done
done

# ============================ æ¶ˆèå®éªŒåˆ†æ ============================
echo ""
echo "=== æ­¥éª¤9: æ¶ˆèå®éªŒåˆ†æ ==="

if [ -n "$RESULTS_DIR" ] && [ -f "$RESULTS_DIR/tables/ablation_study.csv" ]; then
    echo "ğŸ“‹ æ¶ˆèå®éªŒç»“æœå¯¹æ¯”:"
    python -c "
import pandas as pd
import matplotlib.pyplot as plt
import os

# è¯»å–æ¶ˆèå®éªŒç»“æœ
ablation_df = pd.read_csv('$RESULTS_DIR/tables/ablation_study.csv')
print(ablation_df[['model_type', 'final_val_loss', 'final_val_ppl', 'best_val_ppl']].round(4))

# ç”Ÿæˆç®€å•çš„å¯¹æ¯”å›¾
plt.figure(figsize=(10, 6))
models = ablation_df['model_type'].tolist()
ppls = ablation_df['best_val_ppl'].tolist()

bars = plt.bar(models, ppls, color=['skyblue', 'lightcoral'])
plt.ylabel('Best Validation Perplexity')
plt.title('Ablation Study: Model Performance Comparison')
plt.grid(True, alpha=0.3)

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
for bar, ppl in zip(bars, ppls):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
             f'{ppl:.2f}', ha='center', va='bottom')

plt.tight_layout()
plt.savefig('$RESULTS_DIR/figures/ablation_summary.png', dpi=300, bbox_inches='tight')
print('âœ… æ¶ˆèå®éªŒæ€»ç»“å›¾å·²ä¿å­˜: $RESULTS_DIR/figures/ablation_summary.png')
    "
else
    echo "â„¹ï¸ æœªæ‰¾åˆ°æ¶ˆèå®éªŒæ•°æ®è¡¨æ ¼"
fi

# ============================ å®Œæˆæ€»ç»“ ============================
echo ""
echo "=== æ­¥éª¤10: å®éªŒå®Œæˆ ==="
echo "å®Œæˆæ—¶é—´: $(date)"
echo ""
echo "ğŸ‰ å®éªŒç»“æœæ±‡æ€»:"
echo "âœ… ç¯å¢ƒé…ç½®å®Œæˆ"
echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ" 
if [ "$TRAINING_NEEDED" = true ]; then
    echo "âœ… æ•°æ®å‡†å¤‡å®Œæˆ"
    echo "âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ ($EXPERIMENT_MODE æ¨¡å¼)"
else
    echo "âœ… ä½¿ç”¨ç°æœ‰è®­ç»ƒç»“æœ"
fi
echo "âœ… è®­ç»ƒç»“æœéªŒè¯å®Œæˆ"
echo "âœ… æ–‡æœ¬ç”Ÿæˆæµ‹è¯•å®Œæˆ"
echo "âœ… æ¶ˆèå®éªŒåˆ†æå®Œæˆ"
echo ""
echo "ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:"
if [ -n "$MODEL_DIR" ]; then
    echo "æ¨¡å‹æ–‡ä»¶: $MODEL_DIR/"
fi
if [ -n "$RESULTS_DIR" ]; then
    echo "è®­ç»ƒæ›²çº¿: $RESULTS_DIR/figures/"
    echo "æ•°æ®è¡¨æ ¼: $RESULTS_DIR/tables/"
    echo "è®­ç»ƒæ—¥å¿—: $RESULTS_DIR/logs/"
fi
echo ""
echo "================================================================"
echo "                  å¤ç°è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼"
echo "================================================================"
