#!/bin/bash

# =============================================================================
# LLM Midterm Transformer - å®Œæ•´å¤ç°è„šæœ¬
# ä½œè€…ï¼šå­£æœˆå«
# å­¦å·ï¼š25120410
# æè¿°ï¼šä¸€é”®å¤ç°Transformerè®­ç»ƒå’Œç”Ÿæˆå…¨è¿‡ç¨‹
# =============================================================================

set -e  # é‡åˆ°ä»»ä½•é”™è¯¯ç«‹å³é€€å‡º

echo "================================================================"
echo "           LLM Midterm Transformer å¤ç°è„šæœ¬"
echo "================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
echo ""

# ============================ å‚æ•°é…ç½® ============================
SEED=42
PROJECT_DIR="/data0/yhji/llm-midterm-transformer"
PYTHON_PATH="$PROJECT_DIR/src"
EXPERIMENT_MODE=${1:-"ablation"}  # é»˜è®¤è¿›è¡Œæ¶ˆèå®éªŒ

# ============================ ç¯å¢ƒæ£€æŸ¥ ============================
echo "=== æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥ ==="

# æ£€æŸ¥condaç¯å¢ƒ
if ! conda info --envs | grep -q "llm_toy"; then
    echo "åˆ›å»ºcondaç¯å¢ƒ: llm_toy"
    conda create -n llm_toy python=3.10 -y
else
    echo "æ‰¾åˆ°condaç¯å¢ƒ: llm_toy"
fi

# æ¿€æ´»ç¯å¢ƒ
echo "æ¿€æ´»condaç¯å¢ƒ..."
eval "$(conda shell.bash hook)"
conda activate llm_toy

# æ£€æŸ¥Python
echo "Pythonç‰ˆæœ¬: $(python --version)"

# ============================ ä¾èµ–å®‰è£… ============================
echo ""
echo "=== æ­¥éª¤2: å®‰è£…ä¾èµ– ==="

# æ£€æŸ¥æ˜¯å¦æœ‰requirements.txt
if [ -f "$PROJECT_DIR/requirements.txt" ]; then
    echo "ä½¿ç”¨requirements.txtå®‰è£…ä¾èµ–..."
    pip install -r "$PROJECT_DIR/requirements.txt"
else
    echo "æœªæ‰¾åˆ°requirements.txtï¼Œå®‰è£…æ ¸å¿ƒä¾èµ–..."
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    pip install numpy pandas matplotlib requests tqdm tokenizers
fi

# ============================ ç¯å¢ƒè®¾ç½® ============================
echo ""
echo "=== æ­¥éª¤3: ç¯å¢ƒè®¾ç½® ==="

# è®¾ç½®Pythonè·¯å¾„
export PYTHONPATH="$PROJECT_DIR/src:$PYTHONPATH"
export PYTHONHASHSEED=$SEED

# æ£€æŸ¥å¹¶æ˜¾ç¤ºç°æœ‰ç›®å½•
echo "é¡¹ç›®ç›®å½•ç»“æ„:"
for dir in "checkpoints" "results/figures" "results/tables" "results/logs" "data"; do
    if [ -d "$PROJECT_DIR/$dir" ]; then
        echo "âœ… $PROJECT_DIR/$dir/ (å·²å­˜åœ¨)"
    else
        echo "ğŸ“ åˆ›å»ºç›®å½•: $PROJECT_DIR/$dir/"
        mkdir -p "$PROJECT_DIR/$dir"
    fi
done

echo "é¡¹ç›®ç›®å½•: $PROJECT_DIR"
echo "Pythonè·¯å¾„: $PYTHONPATH"
echo "éšæœºç§å­: $SEED"
echo "å®éªŒæ¨¡å¼: $EXPERIMENT_MODE"

# ============================ æ•°æ®å‡†å¤‡ ============================
echo ""
echo "=== æ­¥éª¤4: æ•°æ®å‡†å¤‡ ==="

cd "$PROJECT_DIR"

# ä¸‹è½½æ•°æ®
echo "ä¸‹è½½è®­ç»ƒæ•°æ®..."
python -c "
from src.data import load_data
print('æ­£åœ¨ä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®...')
tokenizer, train_data, val_data = load_data()
print(f'æ•°æ®åŠ è½½å®Œæˆ!')
print(f'è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}')
print(f'è®­ç»ƒæ•°æ®é•¿åº¦: {len(train_data)}')
print(f'éªŒè¯æ•°æ®é•¿åº¦: {len(val_data)}')
"

# ============================ æ¨¡å‹è®­ç»ƒ ============================
echo ""
echo "=== æ­¥éª¤5: æ¨¡å‹è®­ç»ƒ ==="

cd "$PROJECT_DIR/src"

# æ­£ç¡®çš„GPUæ£€æŸ¥ - ä¿®å¤è½¬ä¹‰é—®é¢˜
echo "GPUçŠ¶æ€:"
python -c "
import torch
if torch.cuda.is_available():
    print(f'CUDAå¯ç”¨: True')
    print(f'GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}')
else:
    print(f'CUDAå¯ç”¨: False')
    print(f'GPUè®¾å¤‡: CPU')
"

# æ ¹æ®æ¨¡å¼é€‰æ‹©è®­ç»ƒæ–¹å¼
case $EXPERIMENT_MODE in
    "ablation")
        echo "å¼€å§‹æ¶ˆèå®éªŒï¼ˆå®Œæ•´Transformer vs Decoder-Onlyï¼‰..."
        echo "è¿™å°†éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…..."
        python train.py ablation
        ;;
    "full")
        echo "å¼€å§‹è®­ç»ƒå®Œæ•´Transformeræ¨¡å‹..."
        python train.py full
        ;;
    "decoder_only")
        echo "å¼€å§‹è®­ç»ƒDecoder-Onlyæ¨¡å‹..."
        python train.py decoder_only
        ;;
    *)
        echo "æœªçŸ¥æ¨¡å¼: $EXPERIMENT_MODEï¼Œä½¿ç”¨é»˜è®¤æ¶ˆèå®éªŒ"
        python train.py ablation
        ;;
esac

# ============================ ç»“æœéªŒè¯ ============================
echo ""
echo "=== æ­¥éª¤6: è®­ç»ƒç»“æœéªŒè¯ ==="

# æ£€æŸ¥ç”Ÿæˆçš„å›¾è¡¨å’Œè¡¨æ ¼
echo "æ£€æŸ¥è®­ç»ƒç»“æœè¾“å‡º..."
if [ -d "$PROJECT_DIR/results" ]; then
    echo "ğŸ“Š è®­ç»ƒç»“æœæ±‡æ€»:"
    
    # æ£€æŸ¥å›¾è¡¨æ–‡ä»¶
    if ls "$PROJECT_DIR/results/figures"/*.png 1> /dev/null 2>&1; then
        echo "âœ… è®­ç»ƒæ›²çº¿å›¾:"
        ls "$PROJECT_DIR/results/figures"/*.png
    else
        echo "âŒ æœªæ‰¾åˆ°è®­ç»ƒæ›²çº¿å›¾"
    fi
    
    # æ£€æŸ¥æ•°æ®è¡¨æ ¼
    if ls "$PROJECT_DIR/results/tables"/*.csv 1> /dev/null 2>&1; then
        echo "âœ… ç»“æœè¡¨æ ¼:"
        ls "$PROJECT_DIR/results/tables"/*.csv
        echo ""
        echo "ğŸ“ˆ æœ€ç»ˆç»“æœ:"
        python -c "
import pandas as pd
import glob
import os

csv_files = glob.glob('$PROJECT_DIR/results/tables/*final_results.csv')
for file in csv_files:
    df = pd.read_csv(file)
    filename = os.path.basename(file)
    print(f'æ–‡ä»¶: {filename}')
    for col in df.columns:
        if 'ppl' in col.lower() or 'loss' in col.lower():
            print(f'  {col}: {df[col].values[0]:.4f}')
    print()
        "
    else
        echo "âŒ æœªæ‰¾åˆ°ç»“æœè¡¨æ ¼"
    fi
else
    echo "âŒ æœªæ‰¾åˆ°resultsç›®å½•"
fi

# ============================ æ–‡æœ¬ç”Ÿæˆ ============================
echo ""
echo "=== æ­¥éª¤7: æ–‡æœ¬ç”Ÿæˆæµ‹è¯• ==="

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
models_to_test=()

if [ -f "$PROJECT_DIR/checkpoints/full_transformer_best.pt" ]; then
    models_to_test+=("full_transformer")
fi

if [ -f "$PROJECT_DIR/checkpoints/decoder_only_best.pt" ]; then
    models_to_test+=("decoder_only")
fi

if [ ${#models_to_test[@]} -eq 0 ]; then
    echo "âŒ é”™è¯¯: æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶"
    echo "è¯·å…ˆè¿è¡Œè®­ç»ƒæ­¥éª¤"
    exit 1
fi

echo "æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: ${models_to_test[*]}"
echo "å¼€å§‹ç”Ÿæˆæµ‹è¯•..."

# æµ‹è¯•ä¸åŒçš„prompt
prompts=("To be, or not to be" "Once upon a time" "The future of AI" "Love is" "In the beginning")

for model_type in "${models_to_test[@]}"; do
    echo ""
    echo "ğŸ” æµ‹è¯•æ¨¡å‹: $model_type"
    echo "========================================"
    
    for prompt in "${prompts[@]}"; do
        echo ""
        echo "Prompt: \"$prompt\""
        echo "ç”Ÿæˆç»“æœ:"
        
        # è°ƒç”¨ç”Ÿæˆè„šæœ¬ - ä¿®å¤è½¬ä¹‰é—®é¢˜
        cd "$PROJECT_DIR/src"
        python -c "
import torch
import sys
import os
sys.path.append('.')

try:
    from generate import generate_full_transformer, generate_decoder_only
    from data import load_data
    from model import FullTransformer, DecoderOnlyTransformer
    
    # åŠ è½½tokenizerå’Œæ¨¡å‹
    tokenizer, _, _ = load_data()
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    model_type = '$model_type'
    prompt = '$prompt'
    
    if model_type == 'full_transformer':
        model = FullTransformer(tokenizer.vocab_size)
        model.load_state_dict(torch.load('../checkpoints/full_transformer_best.pt', map_location=device))
        model.to(device)
        result = generate_full_transformer(model, tokenizer, prompt, max_new_tokens=50, temperature=0.8)
    else:
        model = DecoderOnlyTransformer(tokenizer.vocab_size)
        model.load_state_dict(torch.load('../checkpoints/decoder_only_best.pt', map_location=device))
        model.to(device)
        result = generate_decoder_only(model, tokenizer, prompt, max_new_tokens=50, temperature=0.8)
    
    print(result)
except Exception as e:
    print(f'ç”Ÿæˆé”™è¯¯: {e}')
    import traceback
    traceback.print_exc()
        "
        echo "----------------------------------------"
    done
done

# ============================ æ¶ˆèå®éªŒåˆ†æ ============================
echo ""
echo "=== æ­¥éª¤8: æ¶ˆèå®éªŒåˆ†æ ==="

if [ -f "$PROJECT_DIR/results/tables/ablation_study.csv" ]; then
    echo "ğŸ“‹ æ¶ˆèå®éªŒç»“æœå¯¹æ¯”:"
    python -c "
import pandas as pd
import matplotlib.pyplot as plt
import os

# è¯»å–æ¶ˆèå®éªŒç»“æœ
ablation_df = pd.read_csv('$PROJECT_DIR/results/tables/ablation_study.csv')
print(ablation_df[['model_type', 'final_val_loss', 'final_val_ppl', 'best_val_ppl']].round(4))

# ç”Ÿæˆç®€å•çš„å¯¹æ¯”å›¾
plt.figure(figsize=(10, 6))
models = ablation_df['model_type'].tolist()
ppls = ablation_df['best_val_ppl'].tolist()

bars = plt.bar(models, ppls, color=['skyblue', 'lightcoral'])
plt.ylabel('Best Validation Perplexity')
plt.title('Ablation Study: Model Performance Comparison')
plt.grid(True, alpha=0.3)

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
for bar, ppl in zip(bars, ppls):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
             f'{ppl:.2f}', ha='center', va='bottom')

plt.tight_layout()
plt.savefig('$PROJECT_DIR/results/figures/ablation_summary.png', dpi=300, bbox_inches='tight')
print('âœ… æ¶ˆèå®éªŒæ€»ç»“å›¾å·²ä¿å­˜: $PROJECT_DIR/results/figures/ablation_summary.png')
    "
else
    echo "â„¹ï¸ æœªæ‰¾åˆ°æ¶ˆèå®éªŒæ•°æ®è¡¨æ ¼"
fi

# ============================ å®Œæˆæ€»ç»“ ============================
echo ""
echo "=== æ­¥éª¤9: å®éªŒå®Œæˆ ==="
echo "å®Œæˆæ—¶é—´: $(date)"
echo ""
echo "ğŸ‰ å®éªŒç»“æœæ±‡æ€»:"
echo "âœ… ç¯å¢ƒé…ç½®å®Œæˆ"
echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ" 
echo "âœ… æ•°æ®å‡†å¤‡å®Œæˆ"
echo "âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ ($EXPERIMENT_MODE æ¨¡å¼)"
echo "âœ… è®­ç»ƒç»“æœéªŒè¯å®Œæˆ"
echo "âœ… æ–‡æœ¬ç”Ÿæˆæµ‹è¯•å®Œæˆ"
echo "âœ… æ¶ˆèå®éªŒåˆ†æå®Œæˆ"
echo ""
echo "ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:"
echo "æ¨¡å‹æ–‡ä»¶: $PROJECT_DIR/checkpoints/"
echo "è®­ç»ƒæ›²çº¿: $PROJECT_DIR/results/figures/"
echo "æ•°æ®è¡¨æ ¼: $PROJECT_DIR/results/tables/"
echo "è®­ç»ƒæ—¥å¿—: $PROJECT_DIR/results/logs/"
echo ""
echo "================================================================"
echo "                  å¤ç°è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼"
echo "================================================================"
